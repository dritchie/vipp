
var nnutils = require('./utils');
var assert = require('assert');
var _ = require('underscore');
var numeric = require('numeric');


// 'globals' contains the params object
function makeParamPredictor(opts) {

	var globals = opts.globals;
	var stateFeatures = opts.stateFeatures;
	var treeNodeFeatures = opts.treeNodeFeatures;
	var latentN = opts.latentN;
	var nNormalizeSamples = opts.nNormalizeSamples;


	// These get filled in at runtime
	var stateVecDim;
	var treeNodeDataDim;


	// Can't be passed in via opts b/c it needs to be AD'ed.
	var activationFn = function(x) { return 1.7159 * Math.tanh(2/3 * x); };


	var normCache = nnutils.makeInputSampleCache(nNormalizeSamples);
	function getNormalizedStateFeatures(state) {
		return nnutils.normalizeInputs('stateFeatures', stateFeatures(state), normCache);
	}
	function getNormalizedTreeNodeFeatures(node) {
		var features = treeNodeFeatures(node);
		if (features === undefined)
			return undefined;
		return nnutils.normalizeInputs('treeNodeFeatures', features, normCache);
	}


	var HYPERS = [0, 0.1];
	function weightMatrix(name, dims) {
		return paramTensor(name, globals.params, dims, undefined, gaussianERP.sample, HYPERS);
	}
	function biasVector(name, length) {
		return paramTensor(name, globals.params, [length], undefined, gaussianERP.sample, HYPERS);
	}


	// Matrix fused multiply add
	function madd(A, x, b) {
		var n = b.length;
		var m = x.length;
		var out = b.slice();
		for (var i = 0; i < n; i++) {
			for (var j = 0; j < m; j++) {
				out[i] = out[i] + (A[i][j] * x[j]);
			}
		}
		return out;
	}

	// Neural net layer
	function nn(A, x, b) {
		return madd(A, x, b).map(activationFn);
	}


	var latentOrigin = numeric.rep([latentN], 0);
	function getLatentState(treeRoot) {
		if (treeRoot === undefined)
			return latentOrigin;
		var rnnParams = {
			// Params for nn that lifts tree node features into the latent space
			liftWeights: weightMatrix('liftWeights', [latentN, treeNodeDataDim]),
			liftBias: biasVector('liftBias', latentN),
			// Params for nn that merges two child latent states into one
			mergeWeights: weightMatrix('mergeWeights', [latentN, 2*latentN]),
			mergeBias: biasVector('mergeBias', latentN)
			// TODO: Separate params for incorporating lifted node features into merged children?
		};
		return _getLatentState(treeRoot, rnnParams);
	}
	// Subtree computations are cached
	var nodeIdCounter = 0;
	function nextNodeId() { return nodeIdCounter++; }
	function resetNodeIds() { nodeIdCounter = 0; }
	var latentStateCache = {};
	function clearLatentStateCache() { latentStateCache = {}; }
	function _getLatentState(node, rnnParams) {
		if (node.__RNN_ID === undefined) {
			node.__RNN_ID = nextNodeId();
			latentStateCache[node.__RNN_ID] = _getLatentStateImpl(node, rnnParams);
		}
		return latentStateCache[node.__RNN_ID];
	}
	function _getLatentStateImpl(node, rnnParams) {
		var features = getNormalizedTreeNodeFeatures(node);
		var latentState = nn(rnnParams.liftWeights, features, rnnParams.liftBias);
		if (node.children === undefined || node.children.length === 0) {
			return latentState;
		} else {
			assert(node.children.length <= 2);	// Only support binary branching for now
			var childrenLatentState;
			if (node.children.length === 1) {
				childrenLatentState = _getLatentState(node.children[0], rnnParams);
			} else {
				childrenLatentState = nn(
					rnnParams.mergeWeights,
					_getLatentState(node.children[0], rnnParams).concat(_getLatentState(node.children[1], rnnParams)),
					rnnParams.mergeBias
				);
			}
			// TODO: Separate params for incorporating lifted node features into merged children?
			var x = nn(rnnParams.mergeWeights, childrenLatentState.concat(latentState), rnnParams.mergeBias);
			return x;
		}
	}


	return {
		readyToPredict: function() {
			return normCache.hasEnoughSamples();
		},

		collectStateSample: function(state) {
			var features = stateFeatures(state);
			stateVecDim = features.length;
			nnutils.collectSample('stateFeatures', features, normCache);
		},

		collectTreeNodeSample: function(node) {
			var features = treeNodeFeatures(node);
			treeNodeDataDim = features.length;
			nnutils.collectSample('treeNodeFeatures', features, normCache);
		},

		registerNewTreeNode: function(node) {
			// Follow parent pointers back to the root and remove all ids
			while(node) {
				node.__RNN_ID = undefined;
				node = node.parent;
			}
		},

		prepareForRun: function() {
			resetNodeIds();
			clearLatentStateCache();
		},

		predict: function(name, bounds, currState, treeRoot) {
			var currLatentState = getLatentState(treeRoot);
			var predictWeights = weightMatrix('predictWeights_'+name, [bounds.length, stateVecDim + latentN]);
			var predictBias = biasVector('predictBias_'+name, bounds.length);
			var stateFeatures = getNormalizedStateFeatures(currState);
			var params = madd(predictWeights, stateFeatures.concat(currLatentState), predictBias);
			for (var i = 0; i < params.length; i++)
				params[i] = bounds[i].fwd(params[i]);
			return params;
		}
	};
}


module.exports = {
	makeParamPredictor: makeParamPredictor
};




